{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error measures comparing a network with a modified network\n",
    "\n",
    "This notebook presents the sorcecode to compute error measures $\\epsilon$ and $\\epsilon_N$ for random graphs using ``networkx``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "import pandas as pd\n",
    "centrali = \"clos\"\n",
    "quota = 0.5\n",
    "from networkx.algorithms import approximation as approx\n",
    "from matplotlib.pyplot import figure\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function ``cgraph`` returns a random graph with a given node size. Modify this function, e.g. by uncommenting lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cgraph(nodesize):\n",
    "    #G = nx.scale_free_graph(nodesize)\n",
    "    #G = nx.Graph(G.to_undirected())\n",
    "    G = nx.newman_watts_strogatz_graph(nodesize,50,0.5)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the value for ``centrali`` to a particular centrality measure, e.g. ```centrali = \"deg\"\n",
    "centrali = \"bet\"\n",
    "centrali = \"eigen\"\n",
    "centrali = \"clos\"```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrali = \"bet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set ``maxi`` to the maximum number of iterations for $p_B$, ``iterations`` to the number of experiments to carry out. ``nodesize`` refers to the size of the random graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxi = 60 \n",
    "nodesize = 500\n",
    "iterations = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines will save the values for $\\epsilon$ in the dataframe ``df``, and for $\\epsilon_N$ in ``df2``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "for j in range(0,iterations):\n",
    "    q1 = []\n",
    "    c1 = []\n",
    "    c2 = []\n",
    "    c3 = []\n",
    "    c4 = []\n",
    "    c5 = []\n",
    "    c6 = []\n",
    "    for l in range (0, maxi+1, 5):\n",
    "        quote = l/100\n",
    "        G = cgraph(nodesize)\n",
    "        for n in G.nodes():\n",
    "            if random.random() < quote:\n",
    "                G.nodes[n]['attribute'] = True\n",
    "            else:\n",
    "                G.nodes[n]['attribute'] = False\n",
    "        H = G.copy()\n",
    "        dellist = []\n",
    "        for n in H.nodes():\n",
    "            if H.nodes[n]['attribute'] == True:\n",
    "                dellist.append (n)\n",
    "        for n in dellist:\n",
    "            H.remove_node(n)\n",
    "        if True: \n",
    "            if centrali == \"bet\":\n",
    "                bet_centrality = nx.betweenness_centrality(G)#, normalized = True, \n",
    "                                                        #      endpoints = False)\n",
    "                bet_centralityH = nx.betweenness_centrality(H, normalized = True, \n",
    "                                                              endpoints = False)\n",
    "            elif centrali == \"deg\":\n",
    "                bet_centrality = nx.degree_centrality(G)#, normalized = True, \n",
    "                                                        #      endpoints = False)\n",
    "                bet_centralityH = nx.degree_centrality(H)\n",
    "            elif centrali == \"eigen\":\n",
    "                bet_centrality = nx.eigenvector_centrality(G)#, normalized = True, \n",
    "                                                        #      endpoints = False)\n",
    "                bet_centralityH = nx.eigenvector_centrality(H)\n",
    "            elif centrali == \"clos\":\n",
    "                bet_centrality = nx.closeness_centrality(G)#, normalized = True, \n",
    "                                                        #      endpoints = False)\n",
    "                bet_centralityH = nx.closeness_centrality(H)\n",
    "            else: #  \n",
    "                print (\"No valid cm defined.\")\n",
    "            bet_centrality2 = {k: v for k, v in sorted(bet_centrality.items(), key=lambda item: item[1])}\n",
    "            bet_centralityH2 = {k: v for k, v in sorted(bet_centralityH.items(), key=lambda item: item[1])}\n",
    "            for n in dellist:\n",
    "                del (bet_centrality2[n])\n",
    "            # count errors\n",
    "            error = 0\n",
    "            for i in range(0,len(bet_centrality2.keys())):\n",
    "                if list(bet_centrality2.keys())[i] != list(bet_centralityH2.keys())[i]:\n",
    "                    error = error + 1\n",
    "            # count neighbour errors\n",
    "            nerror = 0\n",
    "            for i in range(0,len(bet_centrality2.keys())):\n",
    "                keyhere = list(bet_centrality2.keys())[i]\n",
    "                keythere = list(bet_centralityH2.keys()).index(keyhere)\n",
    "                if i>0 and keythere > 0 and list(bet_centrality2.keys())[i-1] != list(bet_centralityH2.keys())[keythere-1]:\n",
    "                    nerror = nerror + 1\n",
    "                if i<len(bet_centrality2.keys())-1 and keythere<len(bet_centrality2.keys())-1 and list(bet_centrality2.keys())[i+1] != list(bet_centralityH2.keys())[keythere+1]:\n",
    "                    nerror = nerror + 1\n",
    "            q1.append (quote)\n",
    "            c1.append (error/len(bet_centrality2.keys()))\n",
    "            c2.append (nerror/(len(bet_centrality2.keys())*2))\n",
    "        else:\n",
    "            print (str(quote)+\";\"+str(error/len(bet_centrality2.keys()))+\";\"+str(nerror/(len(bet_centrality2.keys())*2))+\";n\")\n",
    "    df = pd.concat (  [df, pd.DataFrame([c1], columns=[q1])])\n",
    "    df2 = pd.concat (  [df2, pd.DataFrame([c2], columns=[q1])])\n",
    "# Save data and boxplots\n",
    "boxplot = df.boxplot(column=q1)#,figsize=(16,8))  \n",
    "boxplot.figure.savefig(centrali+\"-\"+str(nodesize)+'epsilon.pdf')\n",
    "boxplot = df2.boxplot(column=q1)#,figsize=(16,8))  \n",
    "boxplot.figure.savefig(centrali+\"-\"+str(nodesize)+'epsilonN.pdf')\n",
    "df.to_csv(centrali+\"-\"+str(nodesize)+'epsilon.csv')\n",
    "df2.to_csv(centrali+\"-\"+str(nodesize)+'epsilonN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
